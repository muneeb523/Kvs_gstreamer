### KVS Timestamp Handling

KVS SDK defines 64 bit time/timestamp type expressed in 100ns units. This is used in place of frame timecodes/timestamps, representing time offsets/durations and absolute times. The meaning of the value of the type is dependent upon the context of it's application.


#### PTS and DTS timestamps

Producer SDK Frame structure contains two timestamps - PTS (Presentation timestamp) and DTS (Decoding Timestamp). Video (and some Audio) encoders produce both PTS and DTS. PTS represents the timestamp when the particular frame or sample should be reproduced (displayed) while the DTS represents the time when (and the order of) the frame/sample should be decoded. In case of H264/H265 for example, DTS can jump back and forth due to b-frames which are delta encoded against future frame for better encoder quality/compression rate. In this case, the DTS of the b-frame would be after the DTS of the future frame that it’s encoded against. Stream/real-time encoders do not utilize b-frames due to inherently incurred latency as the encoder will have to have an operational “window” which it has to cache in order to make decisions for encoding against future frames.


#### Matroska format

KVS is using MKV (Matroska) format as its underlying packaging format due to it being a standard, being “streamable” and being independent from the underlying elementary stream. KVS utilizes a small portion of the MKV specification. The Producer SDK generates sessions as one continuous MKV stream whereas the fragments returned by the KVS in GetMedia API call each have a header, cluster start and frames which belong to the cluster. 
In most usage cases the customers applications have a single Fragment to MKV Cluster mapping and most Fragments for video would be a single GoP (Group of Pictures). MKV has a single timestamp for both clusters and the frames. Frames are encoded in time units relative to the beginning of the cluster. For example, the cluster frame timestamps could be 0, 33, 66, ... in case of default 1ms timescale, 30 fps and no b-frames. The MKV standard requires that the frames be in a decoding order so we use PTS to timestamp the frames against the cluster start. The timestamp field for the frames has signed 16 bits (effective use of 15 bits) to represent the frame timestamp. The clusters, on the other hand, are encoded as 64bit field and can have arbitrary timestamps as long as it’s monotonically increasing. KVS Producer SDK encodes either Absolute or Relative timestamps in the clusters based on the StreamInfo.StreamCaps.absoluteTimestamp structure member. The Absolute timestamp then is produced directly from the frame or the system clock (depending on Producer SDK StreamInfo.StreamCaps.frameTimestamp field). The Relative timestamp is from the beginning of the presentation - aka - the streaming session start. Most use cases call out for Absolute timestamp usage to ensure the fragment timestamps are monotonically increasing across the streaming sessions.

Example of cluster timestamps:

Key-frame timestamps: 1000, 1001, 1002, ...
Absolute: 1000, 1001, 1002, ...
Relative: 0, 1, 2, ...

KVS service has limits in place to allow for min and max fragment durations. Most optimal, the fragment duration should be 1 - 6 seconds long.


#### SDK Timestamp Modes

Producer SDK (PIC in this case) has two modes of generating timestamps which are frame timestamp or SDK timestamp. In the first mode, the SDK gets the frame timestamp from the frame structure passed in (Frame structure) and processes it. In the SDK mode, the frame timestamp is ignored and a current timestamp is used as the frame is produced by putFrame API. The default GETTIME API is used. The frame mode is the default mode which is used by majority of the media pipelines. The SDK timestamp mode is used when the media pipeline timestamps are missing or jittery. The parameter is part of the StreamInfo StreamCaps structure: https://github.com/awslabs/amazon-kinesis-video-streams-pic/blob/master/src/client/include/com/amazonaws/kinesis/video/client/Include.h#L903


#### Producer and Service Side Timestamp Indexing

KVS has both the Producer and Service-side timestamps indexing. The Producer index is created from the incoming stream itself - whatever is reported by the MKV while the Service side timestamp is generated by the backend at the moment of ingestion. The KVS public consumer API (ex: listFragment) takes a parameter specifying either a Producer or a Service side timestamp. Both indexes are on an absolute time scale - even if a relative mode is used in the SDK to generate cluster timecodes starting from 0. Note: usage of the relative timestamps in the SDK is discouraged due to unanticipated side-effects with the producer time codes in the stream jumping back on each session (as they start from 0) and only very specific applications would need this behavior.

Producer timestamp for a fragment is derived from the value of the timestamp of the first frame in the fragment. If the SDK is configured with absolute timestamps then the first frame timestamp is used as is to index the fragment. If the stream is in relative timestamp mode then the first frame timestamp is added to the streaming session start timestamp, thus generating sequentially increasing timestamps.

Service side timestamps, on the other hand, correspond to the wall-clock NTP-sync-ed timestamp of when the fragment has been received - aka, the timestamp when the Received ACK is generated in the backend.

This has certain implications on the consumer side. For example, if the fragments are ingested in the Offline mode with fast network throughput, most of the fragments Service side timestamps will be very close to each other as it reflects network speed ingestion. The Producer timestamps will still be the ones that the original stream had been generated in. This means that the stream being ingested could have Producer timestamps in the past or in the future, depending on what the meaning of the timestamps are when the producer application generated the stream.


#### Indexing of the Stream for Producer Timestamp

KVS Indexing operates ONLY on Absolute timestamps. The cluster timestamps extracted from the MKV are added to the PutMedia Stream Start parameter. For Absolute timestamp mode, the SDK doesn’t add Stream Start which equates to 0. For Relative timestamp mode, the SDK adds the Session Start (when the PutMedia called by calling the default GETTIME API). The net result is that the Producer Timestamp index on the backend is absolute regardless of whether the ingestion is absolute or relative. However, the backend doesn’t modify the stream bits so the customers using relative timestamps can still query absolute producer times and retrieve a stream that’s timestamped against the session start.

NOTE on Relative Timestamp Use Cases: The relative timestamp use cases are very limited and were requested by a few customers. In their case, the producer was an intermittent producer and they needed to get a clip that starts from 0. The default mode is Absolute.


#### Producer and Consumer Streaming Sessions and Fragments

Producer SDK operates on frames at its lowest granularity. The frames are collected into Fragments (mostly representing MKV Clusters). The SDK then creates a Streaming Session which corresponds to a single PutMedia call. The SDK creates a new session on token rotation or when re-trying a failed connection. The SDK packages a single MKV header for each session with following multiple clusters corresponding to that session. The backend, on the other hand, prepends the MKV header to EVERY fragment. This is done so the fragment is self-contained and can be played back from any point. The result, however, is that the GetMedia API will result in every fragment having a full MKV header resulting in a full MKV clip. Most players will fail to playback “stitched” together full MKV clips.


#### Consumer Parser Library

Consumer parser library consists of the core parser object and multiple visitors. One of the features of the parser library is a segment merger which concatenates the MKV fragments retrieved from the backend and removes the MKV headers.
The parser library itself parses out the timestamp as is from the MKV. The visitors then process the timestamp. 
The Segment merger fails when it discovers a “drift” back of the timestamps which can happen for relative timestamp mode fragments on a new streaming session.
Producer SDK has an ability to specify the streaming sessions belong to the same stream. SegmentUuid is used for this purpose (see MKV specification https://www.matroska.org/technical/elements.html). The StreamInfo.StreamCaps.segmentUuid can be set by the application to a specific value which would then generate MKV header with that particular SegmentUuid instead of a random one. The consumer clients using the parser library and/or the output segment merger sample can then attempt to either stitch the sessions together by modifying the packaging timestamps to monotonically increase or by outputting separate files - depending on the scenario.
For absolute timestamp mode, it is straight forward to stitch fragments from different putMedia sessions as the time should have no conflict if producer side frame timestamps are properly set. But absolute timestamp might have playback issue on some players so an option to provide output of mkv file starting from 0 would be nice to have.
For relative timestamp mode, it is inevitable to get multiple timestamp starting from 0 issue when multiple putMedia session/producer start stop comes into picture. Use cases noticed now can be either just gathering multiple clips and retrieve them in one file with timestamp properly adjusted to be playable or gathering multiple clips and passing them into different output channels. 
